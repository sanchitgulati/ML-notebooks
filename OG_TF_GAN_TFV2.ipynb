{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanchitgulati/ML-notebooks/blob/main/OG_TF_GAN_TFV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9aMFvFjcoI_v"
      },
      "outputs": [],
      "source": [
        "# Copyright 2018 The TensorFlow GAN Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35cp5a7vN9V8"
      },
      "source": [
        "# TF-GAN Tutorial\n",
        "\n",
        "Tutorial authors: joelshor@, westbrook@\n",
        "\n",
        "\n",
        "Updated for TensorFlow 2 : sanchitgulati@"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "83-azWpoYsDg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Check that imports for the rest of the file work.\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Allow matplotlib images to render immediately.\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iUBez2oRbKcp",
        "outputId": "6da149e6-aeb2-4a91-c223-4b4fa159f3c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI8zy5Bz65pa"
      },
      "source": [
        "## Unconditional MNIST with GANEstimator\n",
        "\n",
        "This exercise uses TF-GAN's GANEstimator and the MNIST dataset to create a GAN for generating fake handwritten digits.\n",
        "\n",
        "### MNIST\n",
        "\n",
        "The [MNIST dataset](https://wikipedia.org/wiki/MNIST_database) contains tens of thousands of images of handwritten digits. We'll use these images to train a GAN to generate fake images of handwritten digits. This task is small enough that you'll be able to train the GAN in a matter of minutes.\n",
        "\n",
        "### GANEstimator\n",
        "\n",
        "TensorFlow's Estimator API that makes it easy to train models. TF-GAN offers `GANEstimator`, an Estimator for training GANs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxrYrU887Mns"
      },
      "source": [
        "### Input Pipeline\n",
        "\n",
        "We set up our input pipeline by defining an `input_fn`. in the \"Train and Eval Loop\" section below we pass this function to our GANEstimator's `train` method to initiate training.  The `input_fn`:\n",
        "\n",
        "1.  Generates the random inputs for the generator.\n",
        "2.  Uses `tensorflow_datasets` to retrieve the MNIST data.\n",
        "3.  Uses the tf.data API to format the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Zs8kdV0w7Rtq"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "def input_fn(mode, params):\n",
        "  assert 'batch_size' in params\n",
        "  assert 'noise_dims' in params\n",
        "  bs = params['batch_size']\n",
        "  nd = params['noise_dims']\n",
        "  split = 'train' if mode == tf.estimator.ModeKeys.TRAIN else 'test'\n",
        "  shuffle = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  just_noise = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "  \n",
        "  noise_ds = (tf.data.Dataset.from_tensors(0).repeat()\n",
        "              .map(lambda _: tf.random.normal([bs, nd])))\n",
        "  \n",
        "  if just_noise:\n",
        "    return noise_ds\n",
        "\n",
        "  def _preprocess(element):\n",
        "    # Map [0, 255] to [-1, 1].\n",
        "    images = (tf.cast(element['image'], tf.float32) - 127.5) / 127.5\n",
        "    return images\n",
        "\n",
        "  images_ds = (tfds.load('mnist:3.*.*', split=split)\n",
        "               .map(_preprocess)\n",
        "               .cache()\n",
        "               .repeat())\n",
        "  if shuffle:\n",
        "    images_ds = images_ds.shuffle(\n",
        "        buffer_size=10000, reshuffle_each_iteration=True)\n",
        "  images_ds = (images_ds.batch(bs, drop_remainder=True)\n",
        "               .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "  return tf.data.Dataset.zip((noise_ds, images_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6aboJBr8Rig"
      },
      "source": [
        "Download the data and sanity check the inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "zEhgLuGo8OGc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "699e6988-5af2-4084-8fed-4a7766d1dccd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-660913e12fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m# Iterating over the grid returns the Axes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mrgb_image_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_image_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    696\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 698\u001b[0;31m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0m\u001b[1;32m    699\u001b[0m                             .format(self._A.shape))\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (28, 28, 1, 3) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 200 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAIiklEQVR4nO3dsYsc5xkG8OfLGTfqBKlkgx0IFkqqCGLcqFaCII2LuHBlcKU/ICL/htMIcxg3Tp3u2jQpEhUBBxTjuIlNQIRUbpIIJoUEmZPvtHPa/Ubzvff7wRR73Lx6WO71ze7tPG7TNAWo6XsvOwDQjwWHwiw4FGbBoTALDoVZcChs54K31o5ba49aa5+vEQg4nCW/wT9JcrtzDqCDnQs+TdPvk/xrhSzAgb1yqEGttQ+TfJgkV65cuXn9+vUXmvPgwYN/TtP0/d5zR8x8qLky18t8rmmadh5J3kjy+ZLvnaYpN2/enF5Ukj+tPXfEzPvMlbl25vnhXXQozIJDYUv+TPZZkj8keau19nVr7YP+sYBD2Pkm2zRN760RBDg8l+hQmAWHwiw4FGbBoTALDoVZcChs0YK31m631v7aWvuytfar3qGAw1jyQZejJL9J8rMkN5K811q70TsYsL8lv8F/muTLaZq+mqbpP0l+m+QXfWMBh7Bkwa8l+fvs8ddPvwZsXJf7wZP8e4+Kp7fWmNtz9gBze86WeZ3Z3/l5PtOu+0mTvJPkZPb4XpJ7O85ZdK/qRc/tNXfEzPvMlbl25vmx5BL9j0l+2Fp7s7X2apJfJvndov96AC/VkrvJHrfW7iY5SXKU5Hiapr90TwbsbeeCt9aOk9xJ8miaph8vnHt/j0zPO7fX3J6ztzi352yZ15m96Nz29Hr+/G9o7VaSb5N8eoEFBzZAbTIUpjZ5oMwj1vnKrDb5lKhN7j5X5tqZ54e7yaAwCw6FqU2GwtQmQ2Eu0aEwCw6FWXAozIJDYRYcCrPgUJjaZChMbTIUpjYZCltyu+hZtclvP/tNAzRcalVdZ7bM68w+WKvqu0k+nj1+P8lHO87ZXMPlrnNHy7zPXJlrZ54fSy7Rv0ny+uzxa0+/Bmyc2mQobMlr8PtJriZ5mCevv5fUJm+x4VKr6jqzZV5ntlZVuOy0qkJhWlUHyjxi26fMWlVPiVbV7nNlrp15frjZBAqz4FCYVlUoTKsqFOYSHQqz4FCYBYfCLDgUZsGhMAsOhWlVhcK0qkJhWlWhsCULflar6rU+cYBD6nI/eLZZYas2eZ3ZMq8z+2C1ye8kOZk9vpfk3o5zNldhu+vc0TLvM1fm2pnnh1ZVKGzJ3WSPW2t3k5wkOcqyVlVgA3YueGvtOMmdJI+m5a2qW6ywVZu8zmyZ15mtNhkuO7XJUJja5IEyj1jnK7Pa5FOiNrn7XJlrZ54f7iaDwiw4FKY2GQpTmwyFuUSHwiw4FGbBoTALDoVZcCjMgkNhapOhMLXJUJjaZChsye2iZ9Umv/3sNw3QcKlVdZ3ZMq8z+2Ctqu8m+Xj2+P0kH+04Z3MNl7vOHS3zPnNlrp15fiy5RP8myeuzx689/RqwcWqTobAlr8HvJ7ma5GGevP5eUpu8xYZLrarrzJZ5ndlaVeGy06oKhWlVHSjziG2fMmtVPSVaVbvPlbl25vnhZhMozIJDYVpVoTCtqlCYS3QozIJDYRYcCrPgUJgFh8IsOBSmVRUK06oKhWlVhcK0qg6UecS2T5m1qm6ihXK0zPvMlbl25vmhVRUK06oKhS25m+xxa+1ukpMkR9GqetFztzi352yZ15l9sFbV4yR3kjyatKrCUJZcon+S5HbnHEAHapOhMLXJA2Uesc5XZrXJp0Rtcve5MtfOPD/cTQaFWXAoTG0yFKY2GQpziQ6FWXAozIJDYRYcCrPgUJgFh8LUJkNhapOhMLXJUJja5IEyj1jnK7Pa5MXn9po7YuZ95spcO/P8UJsMhalNhsKWvAa/n+Rqkod58vpbbfLFzt3i3J6zZV5n9sFqk28l+TbJp5PaZBiKVlUoTKvqQJlHbPuUWavqKdGq2n2uzLUzzw83m0BhFhwK06oKhWlVhcJcokNhFhwKs+BQmAWHwiw4FGbBoTCtqlCYVlUoTKsqFKZVdaDMI7Z9yqxVdRMtlKNl3meuzLUzzw+tqlCYVlUoTKtq/9lbnNtztszrzNaqCpedVlUozEdVoTC1yQNlHrHOV2a1yadEbXL3uTLXzjw/XKJDYVpVoTCtqlCYS3QozIJDYRYcCrPgUJgFh8IsOBRmwaEwtclQmNpkKExtMhSmNnmgzCPW+cqsNnkTNbOjZd5nrsy1M88PtclQmNpkKExtcv/ZW5zbc7bM68xWmwyXndpkKEyr6kCZR2z7lFmr6inRqtp9rsy1M88PN5tAYRYcClObDIWpTYbCXKJDYRYcCrPgUJgFh8IsOBRmwaEwrapQmFZVKEyrKhSmVXWgzCO2fcqsVXUTLZSjZd5nrsy1M88PrapQmFZVKEyrav/ZW5zbc7bM68zWqgqXnVZVKMxHVaEwtckDZR6xzldmtcmnRG1y97ky1848P1yiQ2FaVaEwrapQmEt0KMyCQ2EWHAqz4FCYBYfCLDgUZsGhMLXJUJjaZChMbTIUpjZ5oMwj1vnKrDZ5EzWzo2XeZ67MtTPPD7XJUJjaZChsye2ij1trd5OcJDmK2uSLnrvFuT1ny7zO7MPUJgPj8kk2KMyCQ2EHXfB9PtLaWjturT067++CLzq719xds7f4XMi8TuaX9VycaZ+/8T3zd7mjJH9L8oMkryb5c5IbFzj/VpKf5Ix65n1m95r7vNlbfS5krvszd95xyN/ge32kdXr+/yLphWf3mrtj9iafC5nXyfySnoszHXLBz/pI67WNzx5tbs/ZMq8zu2fm7/AmGxR2yAXv+ZHWXrNHm9tztszrzF73o99LX9wvePH/SpKvkryZ/7958KMLzngjZ78xsdfsXnPPm73l50Lmmj9z537vRQYv+Id/nuSLPHmX8NcXPPezJP9I8t88eV3ywSFm95q7a/YWnwuZa//MnXX4qCoU5k02KMyCQ2EWHAqz4FCYBYfCLDgUZsGhsP8BNtRl0a+Sz2oAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "# params = {'batch_size': 100, 'noise_dims':64}\n",
        "# with tf.Graph().as_default():\n",
        "#   ds = input_fn(tf.estimator.ModeKeys.TRAIN, params)\n",
        "#   numpy_imgs = next(iter(tfds.as_numpy(ds)))[1]\n",
        "\n",
        "# fig = plt.figure(figsize=(4., 4.))\n",
        "# grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "#                  nrows_ncols=(10, 10),  # creates 2x2 grid of axes\n",
        "#                  axes_pad=0.1,  # pad between axes in inch.\n",
        "#                  )\n",
        "\n",
        "# for ax, im in zip(grid, numpy_imgs):\n",
        "#   # Iterating over the grid returns the Axes.\n",
        "#   rgb_image_data = np.stack((im, im, im), axis=-1)  \n",
        "#   ax.imshow(rgb_image_data)\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "\n",
        "im1 = np.arange(100).reshape((10, 10))\n",
        "im2 = im1.T\n",
        "im3 = np.flipud(im1)\n",
        "im4 = np.fliplr(im2)\n",
        "\n",
        "im1\n",
        "fig = plt.figure(figsize=(4., 4.))\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, [im1, im2, im3, im4]):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(im)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "MHMpskpJrX79",
        "outputId": "954052a0-3893-48ef-c447-721a97ac2057"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sAetutZ9t93"
      },
      "source": [
        "### Neural Network Architecture\n",
        "\n",
        "To build our GAN we need two separate networks:\n",
        "\n",
        "*  A generator that takes input noise and outputs generated MNIST digits\n",
        "*  A discriminator that takes images and outputs a probability of being real or fake\n",
        "\n",
        "We define functions that build these networks. In the GANEstimator section below we pass the builder functions to the `GANEstimator` constructor. `GANEstimator` handles hooking the generator and discriminator together into the GAN. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ9n-jw_MG6C"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense,BatchNormalization,Conv2DTranspose,Conv2D\n",
        "\n",
        "def _dense(units, l2_weight):\n",
        "  return Dense(units, None,\n",
        "      kernel_initializer=tf.keras.initializers.glorot_uniform,\n",
        "      kernel_regularizer=tf.keras.regularizers.l2(l=l2_weight),\n",
        "      bias_regularizer=tf.keras.regularizers.l2(l=l2_weight))\n",
        "\n",
        "def _batch_norm():\n",
        "  return BatchNormalization(momentum=0.999, epsilon=0.001)\n",
        "\n",
        "def _deconv2d(filters, kernel_size, stride, l2_weight):\n",
        "  return Conv2DTranspose(filters, [kernel_size, kernel_size], strides=[stride, stride], \n",
        "      activation=tf.nn.relu, padding='same',\n",
        "      kernel_initializer=tf.keras.initializers.glorot_uniform,\n",
        "      kernel_regularizer=tf.keras.regularizers.l2(l=l2_weight),\n",
        "      bias_regularizer=tf.keras.regularizers.l2(l=l2_weight))\n",
        "\n",
        "def _conv2d(filters, kernel_size, stride, l2_weight):\n",
        "  return Conv2D(filters, [kernel_size, kernel_size], strides=[stride, stride], \n",
        "      activation=None, padding='same',\n",
        "      kernel_initializer=tf.keras.initializers.glorot_uniform,\n",
        "      kernel_regularizer=tf.keras.regularizers.l2(l=l2_weight),\n",
        "      bias_regularizer=tf.keras.regularizers.l2(l=l2_weight))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### unconditional_generator"
      ],
      "metadata": {
        "id": "VfHQQLLsIufy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHkpn6ks90_R"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import ReLU,Reshape,Activation\n",
        "\n",
        "def unconditional_generator(noise):\n",
        "  model = Sequential() #Here we initiate the sequential model\n",
        "  \"\"\"Generator to produce unconditional MNIST images.\"\"\"\n",
        "  weight_decay=2.5e-5\n",
        "  units = 1024\n",
        "  height = 28\n",
        "  width = 28\n",
        "  channels = 1\n",
        "\n",
        "  model.add(tf.keras.Input(shape=(28, 28, 1)))\n",
        "  model.add(_dense(units, weight_decay))\n",
        "  model.add(_batch_norm())\n",
        "  model.add(ReLU())\n",
        "  model.add(_dense(7 * 7 * 256, weight_decay))\n",
        "  model.add(_batch_norm())\n",
        "  model.add(ReLU())\n",
        "  model.add(_conv2d(filters=64, kernel_size=4, stride=2,l2_weight = weight_decay))\n",
        "  model.add(_deconv2d(filters=64, kernel_size=4,stride=2, l2_weight=weight_decay))\n",
        "  # Make sure that generator output is in the same range as `inputs`\n",
        "  # ie [-1, 1].\n",
        "  model.add(_conv2d(filters=1, kernel_size=4, stride=1, l2_weight=0.0))\n",
        "  model.add(Activation(tf.tanh))\n",
        "  return model.outputs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### unconditional_discriminator"
      ],
      "metadata": {
        "id": "ryqXO0idIrZe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-ZqQ4_thIrP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import LeakyReLU,Flatten\n",
        "\n",
        "\n",
        "def unconditional_discriminator(img, conditioning):\n",
        "  weight_decay=2.5e-5\n",
        "  model = Sequential() #Here we initiate the sequential model\n",
        "  # del conditioning\n",
        "  \n",
        "  model.add(tf.keras.Input(shape=(28, 28, 1)))\n",
        "  model.add(_conv2d(64, 4, 2, weight_decay))\n",
        "  model.add(LeakyReLU())\n",
        "  \n",
        "  model.add(_conv2d(128, 4, 2, weight_decay))\n",
        "  model.add(LeakyReLU())\n",
        "  model.add(Flatten())\n",
        "  model.add(_dense(1024, weight_decay))\n",
        "  model.add(_batch_norm())\n",
        "  model.add(LeakyReLU())\n",
        "  model.add(_dense(1, weight_decay))\n",
        "\n",
        "  return model.outputs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhTAjxnyPS5e"
      },
      "source": [
        "### Evaluating Generative Models, and evaluating GANs\n",
        "\n",
        "\n",
        "TF-GAN provides some standard methods of evaluating generative models. In this example, we measure:\n",
        "\n",
        "*  Inception Score: called `mnist_score` below.\n",
        "*  Frechet Inception Distance\n",
        "\n",
        "We apply a pre-trained classifier to both the real data and the generated data calculate the *Inception Score*.  The Inception Score is designed to measure both quality and diversity. See [Improved Techniques for Training GANs](https://arxiv.org/abs/1606.03498) by Salimans et al for more information about the Inception Score.\n",
        "\n",
        "*Frechet Inception Distance* measures how close the generated image distribution is to the real image distribution.  See [GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium](https://arxiv.org/abs/1706.08500) by Heusel et al for more information about the Frechet Inception distance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jF-FW5LPTn6"
      },
      "outputs": [],
      "source": [
        "from tensorflow_gan.examples.mnist import util as eval_util\n",
        "import os\n",
        "\n",
        "def get_eval_metric_ops_fn(gan_model):\n",
        "  real_data_logits = tf.reduce_mean(gan_model.discriminator_real_outputs)\n",
        "  gen_data_logits = tf.reduce_mean(gan_model.discriminator_gen_outputs)\n",
        "  real_mnist_score = eval_util.mnist_score(gan_model.real_data)\n",
        "  generated_mnist_score = eval_util.mnist_score(gan_model.generated_data)\n",
        "  frechet_distance = eval_util.mnist_frechet_distance(\n",
        "      gan_model.real_data, gan_model.generated_data)\n",
        "  return {\n",
        "      'real_data_logits': tf.metrics.mean(real_data_logits),\n",
        "      'gen_data_logits': tf.metrics.mean(gen_data_logits),\n",
        "      'real_mnist_score': tf.metrics.mean(real_mnist_score),\n",
        "      'mnist_score': tf.metrics.mean(generated_mnist_score),\n",
        "      'frechet_distance': tf.metrics.mean(frechet_distance),\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxF2-gWHHaej"
      },
      "source": [
        "### GANEstimator\n",
        "\n",
        "The `GANEstimator` assembles and manages the pieces of the whole GAN model. The `GANEstimator` constructor takes the following compoonents for both the generator and discriminator:\n",
        "\n",
        "*  Network builder functions: we defined these in the \"Neural Network Architecture\" section above.\n",
        "*  Loss functions: here we use the wasserstein loss for both.\n",
        "*  Optimizers: here we use `tf.train.AdamOptimizer` for both generator and discriminator training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBd8Vg7lHit8"
      },
      "outputs": [],
      "source": [
        "# Get the global step variable\n",
        "\n",
        "train_batch_size = 32 #@param\n",
        "noise_dimensions = 64 #@param\n",
        "generator_lr = 0.001 #@param\n",
        "discriminator_lr = 0.0002 #@param\n",
        "beta_1 = 0.5  #@param\n",
        "params_fn = {'mode':tf.estimator.ModeKeys.TRAIN,'batch_size': train_batch_size, 'noise_dims': noise_dimensions}\n",
        "\n",
        "\n",
        "gan_estimator = tfgan.estimator.GANEstimator(\n",
        "    generator_fn=unconditional_generator,\n",
        "    discriminator_fn=unconditional_discriminator,\n",
        "    generator_loss_fn=tfgan.losses.wasserstein_generator_loss,\n",
        "    discriminator_loss_fn=tfgan.losses.wasserstein_discriminator_loss,\n",
        "    params=params_fn,\n",
        "    generator_optimizer= tf.compat.v1.train.AdamOptimizer(generator_lr, 0.5),\n",
        "    discriminator_optimizer= tf.compat.v1.train.AdamOptimizer(discriminator_lr, 0.5),\n",
        "    get_eval_metric_ops_fn=get_eval_metric_ops_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1uldXfUfstT"
      },
      "source": [
        "### Train and eval loop\n",
        "\n",
        "The `GANEstimator`'s `train()` method initiates GAN training, including the alternating generator and discriminator training phases.\n",
        "\n",
        "The loop in the code below calls `train()` repeatedly in order to periodically display generator output and evaluation results. But note that the code below does not manage the alternation between discriminator and generator: that's all handled automatically by `train()`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gan_estimator"
      ],
      "metadata": {
        "id": "vH2d8uirhosz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH6gcvcwHvSn"
      },
      "outputs": [],
      "source": [
        "# # Disable noisy output.\n",
        "# tf.autograph.set_verbosity(0, False)\n",
        "\n",
        "# import time\n",
        "# steps_per_eval = 500 \n",
        "# max_train_steps = 5000\n",
        "# batches_for_eval_metrics = 100\n",
        "\n",
        "# # Used to track metrics.\n",
        "# steps = []\n",
        "# real_logits, fake_logits = [], []\n",
        "# real_mnist_scores, mnist_scores, frechet_distances = [], [], []\n",
        "\n",
        "# cur_step = 0\n",
        "# start_time = time.time()\n",
        "# while cur_step < max_train_steps:\n",
        "#   next_step = min(cur_step + steps_per_eval, max_train_steps)\n",
        "\n",
        "#   start = time.time()\n",
        "#   gan_estimator.train(input_fn, max_steps=next_step)\n",
        "#   steps_taken = next_step - cur_step\n",
        "#   time_taken = time.time() - start\n",
        "#   print('Time since start: %.2f min' % ((time.time() - start_time) / 60.0))\n",
        "#   print('Trained from step %i to %i in %.2f steps / sec' % (\n",
        "#       cur_step, next_step, steps_taken / time_taken))\n",
        "#   cur_step = next_step\n",
        "  \n",
        "#   # Calculate some metrics.\n",
        "#   metrics = gan_estimator.evaluate(input_fn, steps=batches_for_eval_metrics)\n",
        "#   steps.append(cur_step)\n",
        "#   real_logits.append(metrics['real_data_logits'])\n",
        "#   fake_logits.append(metrics['gen_data_logits'])\n",
        "#   real_mnist_scores.append(metrics['real_mnist_score'])\n",
        "#   mnist_scores.append(metrics['mnist_score'])\n",
        "#   frechet_distances.append(metrics['frechet_distance'])\n",
        "#   print('Average discriminator output on Real: %.2f  Fake: %.2f' % (\n",
        "#       real_logits[-1], fake_logits[-1]))\n",
        "#   print('Inception Score: %.2f / %.2f  Frechet Distance: %.2f' % (\n",
        "#       mnist_scores[-1], real_mnist_scores[-1], frechet_distances[-1]))\n",
        "  \n",
        "#   # Vizualize some images.\n",
        "#   iterator = gan_estimator.predict(\n",
        "#       input_fn, hooks=[tf.train.StopAtStepHook(num_steps=21)])\n",
        "#   try:\n",
        "#     imgs = np.array([next(iterator) for _ in range(20)])\n",
        "#   except StopIteration:\n",
        "#     pass\n",
        "#   tiled = tfgan.eval.python_image_grid(imgs, grid_shape=(2, 10))\n",
        "#   plt.axis('off')\n",
        "#   plt.imshow(np.squeeze(tiled))\n",
        "#   plt.show()\n",
        "  \n",
        "  \n",
        "# # Plot the metrics vs step.\n",
        "# plt.title('MNIST Frechet distance per step')\n",
        "# plt.plot(steps, frechet_distances)\n",
        "# plt.figure()\n",
        "# plt.title('MNIST Score per step')\n",
        "# plt.plot(steps, mnist_scores)\n",
        "# plt.plot(steps, real_mnist_scores)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JbokGCpdWdvR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}